{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rag and Fine Tuning in LLMs\n",
    "\n",
    "#### Introduction\n",
    "To comprehend the concepts of rag and fine tuning, it is imperative to first understand their origins, which lie in the practical workings of Large Language Models (LLMs). When interacting with an LLM through an application such as ChatGPT, it often feels akin to conversing with a real person. A question is posed, it responds, and a dialogue ensues. This interaction can create the illusion that the LLM possesses genuine intelligence and reasoning capabilities.\n",
    "\n",
    "#### The Illusion of Intelligence\n",
    "However, when the output from the LLM becomes imprecise or incorrect, yet remains confidently presented, it can appear as though the system is being deceptive or \"hallucinating.\" This perception is misleading and complicates the understanding and utilization of LLMs. Therefore, it is essential to reframe the mental model of how these systems operate.\n",
    "\n",
    "#### The Nature of LLMs\n",
    "Large language models used in chat applications are essentially sophisticated auto-complete systems. When initiating a new chat, the LLM begins with a system message, which serves as the initial context for the conversation. For instance, if someone inquires, \"What ingredients do I need to bake a cake?\", the LLM processes this prompt along with the system message and generates a response by auto-completing the document thus far.\n",
    "\n",
    "#### How LLMs Generate Responses\n",
    "The critical point to understand is that the LLM does not retrieve information about cake recipes from a database. Instead, it utilizes its vast, complex map of language patterns to predict and generate text. Given that its training data includes millions of cake recipes, and most recipes share common ingredients, the model is likely to produce an accurate list for a generic cake.\n",
    "\n",
    "#### The Role of Probability\n",
    "This process is fundamentally probabilistic. The LLM's ability to answer questions stems from statistical patterns learned during training, not from any inherent understanding or intelligence. It is crucial to recognize that what appears to be intelligent behavior is actually advanced mathematical computation.\n",
    "\n",
    "#### The Importance of Context\n",
    "A significant realization when working with LLMs is the importance of providing context. This is not something explicitly thought about but rather intuitively applied, similar to natural conversational habits. For example, when asking for cake ingredients, specifying \"carrot cake\" provides essential context. The LLM then processes this context, along with the system message and previous interactions, to generate a relevant response. This principle underlies the effectiveness of \"prompt engineering.\" The more context provided, the more accurately the LLM can complete the chat in a relevant manner.\n",
    "\n",
    "#### Practical Applications\n",
    "This contextual approach also explains why pasting a document, webpage, or video transcript into an LLM and requesting a summary works effectively. By providing text as context, the LLM augments and responds to it, creating the impression that it is reading and summarizing the content according to the specifications.\n",
    "\n",
    "#### Retrieval Augmented Generation (RAG)\n",
    "People often treat chat-based LLM systems as a combination of a search engine and a knowledgeable assistant. They ask the LLM to answer questions or perform tasks, often combining the two. However, as previously explained, the LLM is not a knowledge lookup system but a language transformer. It does not possess actual knowledge but uses a complex map of language to auto-complete sentences based on patterns in its training data. This can lead to incorrect information being presented with high confidence, which can be perceived as hallucination or deception.\n",
    "\n",
    "To address this, the accuracy of LLM outputs can be enhanced by incorporating context. Instead of immediately generating a response, the AI service can retrieve information from a knowledge base, integrate it into the context, and then generate a response. This approach, known as Retrieval Augmented Generation (RAG), was first introduced with the Bing AI system. When a question is asked, it searches the web for relevant information, augments the data, and generates a response. This method is not limited to search engines; LLM systems can retrieve data from any structured source and augment it to generate contextually accurate responses.\n",
    "\n",
    "#### The RAG Flow\n",
    "The RAG system operates as follows: When a request is received, an LLM parses the meaning of the request and transforms it into a query for the relevant data source or knowledge base. This could be a standard database accessed via an API, an array of embeddings, a vector database, or even a cookbook referred to as the grounded truth. The LLM acts as a translator, converting the natural language request into a software query. The grounded truth data source processes the request and returns the data to the LLM. The LLM then combines the original request with the newly retrieved data to produce an answer.\n",
    "\n",
    "To enhance accuracy, an additional verification loop can be implemented. The generated response, along with the retrieved data, is returned to the LLM, which verifies that the response contains only information from the retrieved data. This loop can be repeated as necessary to increase the probability of producing a more accurate response. In practical terms, RAG is akin to providing the LLM with a cookbook when asking for carrot cake ingredients. If a carrot cake recipe exists in the book, the LLM will likely provide that ingredient list instead of a probabilistic response.\n",
    "\n",
    "#### Embeddings: Helping AI Understand Data\n",
    "An important question arises when using RAG: How does the AI system and the grounded source know to provide only relevant information? For example: distinguishing between carrot cake and carrot soup? This is where embeddings come into play. Embeddings are numerical representations of text that capture semantic meaning in multidimensional space.\n",
    "\n",
    "Using an embeddings model converts any string of text into numerical points and vectors. For example: each recipe in a cookbook can be transformed into embeddings and stored in a database. When queried (e.g., \"How do I make vegetable cake?\"), embeddings for both query & recipes are generated & compared - identifying closest matches & retrieving most relevant info.\n",
    "\n",
    "#### Knowledge Graphs\n",
    "While embeddings are powerful tools for understanding data relationships within expansive datasets - they have limitations due inherent ambiguity within language itself (e.g., \"paste\" referring both tomato/toothpaste). Without additional context - embedding systems might return irrelevant matches leading nonsensical results.\n",
    "\n",
    "To address this issue - knowledge graphs add direction/semantic meaning connections between words enhancing understanding relationships between concepts beyond mere word connections alone (e.g., linking \"tomato\" & \"paste\" cooking via \"is used in\" relationship vs linking \"tooth\" & \"paste\" hygiene via \"is part of\" relationship).\n",
    "\n",
    "When querying (e.g., \"What paste do I use make pasta?\") - knowledge graph adds context (\"is used cooking\") ensuring only relevant matches returned improving accuracy responses providing semantic context.\n",
    "\n",
    "#### Fine-Tuning\n",
    "RAG powerful approach improving accuracy outputs but most effective combined other techniques particularly fine-tuning involving providing large set training examples including system messages/prompts/responses foundation model training respond specific types queries specific ways ensuring chatbot responses conform specific tone/include predefined info/perform specific actions reducing variance responses providing direct control over behavior foundation models alone cannot achieve despite challenges extensive training data/multiple iterations refining model trial/error process valuable approach situations consistency/response quality critical.\n",
    "\n",
    "#### RAFT: RAG with Fine-Tuning\n",
    "Building on the concepts of RAG and fine-tuning, RAFT, or Retrieval Augmented Fine-Tuning, addresses the challenge of creating efficient LLM-based AI systems grounded in specialized domain data, such as internal enterprise documents. The process begins by using RAG to fine-tune the LLM on domain-specific data, enabling it to recognize and match patterns within that data. The resulting RAFT model is then used in conjunction with RAG to produce answers that are not only grounded in domain data but also conform to its patterns.\n",
    "\n",
    "The RAFT process leverages the reasoning capabilities of LLM foundation models to create training data for fine-tuning. It involves several steps:\n",
    "1. Generate a set of domain-specific questions matching the types of user queries the system will handle.\n",
    "2. Use RAG to retrieve two types of domain documents: oracle documents containing the answer to the question and distractor documents containing irrelevant information.\n",
    "3. Combine the original question with the associated oracle documents to create a chain-of-thought answer that breaks down the detailed reasoning process.\n",
    "4. Run the fine-tuning process using three types of training examples:\n",
    "   - Question, oracle data, and correct chain-of-thought answers.\n",
    "   - Question, distractor data, and correct chain-of-thought answers.\n",
    "   - Question, a mix of data, and correct chain-of-thought answers.\n",
    "\n",
    "By using a mix of these training examples, the model learns to use relevant oracle data, ignore irrelevant distractor data, and discern what data is relevant for any given question. The new RAFT model, combined with traditional RAG, produces a robust, fine-tuned LLM-based AI system that is firmly grounded in specialized domain knowledge and highly likely to generate relevant and accurate responses.\n",
    "\n",
    "#### Conclusion\n",
    "In summary - understanding rag/fine tuning begins recognizing powerful tools generating text based learned language patterns lacking true intelligence producing remarkably accurate outputs sophisticated probability-based methods foundational knowledge aids better appreciating working refining models various applications strategic use context significantly enhances performance/relevance outputs highlighting importance prompt engineering potential Retrieval Augmented Generation practical applications embeddings/knowledge graphs further enhancing process enabling understanding/retrieving relevant data accurately fine-tuning complements techniques providing consistency/control responses. RAFT further integrates these approaches, ensuring robust and reliable AI systems for specialized domains."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
